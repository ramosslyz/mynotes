# Kubernetes
## Navigation
- **[[#Control Plane Components]]**
- **[[#Node Components]]**
- **[[#Kubernetes Objects]]**
- **[[#Object Names and IDs]]**
- **[[#Namespaces]]**

---
# Kubernetes Components
When you deploy Kubernetes, you get a cluster. A Kubernetes cluster consists of a set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node.
- **Master Node:**
	- The node which manages the k8s worker nde cluster and the deployment of pds on nods.

- **control plane**
	- manages the worker nodes and the Pods in the cluster. In production environments, the control plane usually runs across multiple computers.
- ** Worker Node:** 
	- These nodes typically run the application containers and the other k8s components such as agents and proxies.
- **Pods**
	- A unit of deplyment and addressability in k8s.A pod has its own ip address and can contain one or more containers (subnets,Vlans,zones)

- **Services**
	- A service functions as a proxy to its underlying pods and requests can be load balanced accross replicated pods.

- **Main Components**
	- Key components which are used to manage a k8s cluster include the API Server kubelet and etcd.
	
![[kubernetes.png]]

# Control Plane Components
he control plane's components make global decisions about the cluster (for example, scheduling), as well as detecting and responding to cluster events (for example, starting up a new pod when a deployment's replicas field is unsatisfied).

## kube-apiserver 
The API server is a component of the Kubernetes control plane that exposes the Kubernetes API. The API server is the front end for the Kubernetes control plane.

The main implementation of a Kubernetes API server is kube-apiserver. kube-apiserver is designed to scale horizontallyâ€”that is, it scales by deploying more instances. You can run several instances of kube-apiserver and balance traffic between those instances.
## etcd
Consistent and highly-available key value store used as Kubernetes' backing store for all cluster data.
## kube-scheduler 
Control plane component that watches for newly created Pods with no assigned node, and selects a node for them to run on.

## kube-controller-manager 
Control plane component that runs controller processes.
Logically, each controller is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process.
Some types of these controllers are:

  - **Node controller:** Responsible for noticing and responding when nodes go down.
   - **Job controller:** Watches for Job objects that represent one-off tasks, then creates Pods to run those tasks to completion.
    - **Endpoints controller:** Populates the Endpoints object (that is, joins Services & Pods).
    - **Service Account & Token controllers:** Create default accounts and API access tokens for new namespaces.

## cloud-controller-manager
A Kubernetes control plane component that embeds cloud-specific control logic.The cloud-controller-manager only runs controllers that are specific to your cloud provider. If you are running Kubernetes on your own premises, or in a learning environment inside your own PC, the cluster does not have a cloud controller manager.
The following controllers can have cloud provider dependencies:

-  **Node controller**: For checking the cloud provider to determine if a node has been deleted in the cloud after it stops responding
- **Route controller**: For setting up routes in the underlying cloud infrastructure
 - **Service controller**: For creating, updating and deleting cloud provider load balancers
# Node Components
Node components run on every node, maintaining running pods and providing the Kubernetes runtime environment.
## kubelet
An agent that runs on each node in the cluster. It makes sure that containers are running in a Pod.
## kube-proxy
kube-proxy is a network proxy that runs on each node in your cluster, implementing part of the Kubernetes Service concept.
kube-proxy maintains network rules on nodes. These network rules allow network communication to your Pods from network sessions inside or outside of your cluster.
**kube-proxy uses the operating system packet filtering layer if there is one and it's available. Otherwise, kube-proxy forwards the traffic itself.**
## Container runtime
The container runtime is the software that is responsible for running containers.
Kubernetes supports several container runtimes: **Docker**, **containerd**,** CRI-O**, and any implementation of the Kubernetes CRI (Container Runtime Interface).

# Kubernetes Objects
Kubernetes objects are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Specifically, they can describe:

- What containerized applications are running (and on which nodes).
- The resources available to those applications.
- The policies around how those applications behave, such as restart policies, upgrades, and fault-tolerance.

A Kubernetes object is a *"record of intent*"--once you create the object, the Kubernetes system will constantly work to ensure that object exists.
To work with Kubernetes objects--whether to **create**, **modify**, or **delete** them--you'll need to use the **Kubernetes API**. When you use the **kubectl command-line interface, for example, the CLI makes the necessary Kubernetes API calls for you**. You can also use the Kubernetes API directly in your own programs using one of the Client Libraries.

## Describing a Kubernetes object 
When you create an object in Kubernetes, you **must** provide the object spec that describes its desired state, as well as some basic information about the object (such as a name). When you use the Kubernetes API to create the object (either directly or via kubectl), that API request must include that information as JSON in the request body. Most often, you provide the information to kubectl in a .yaml file. kubectl converts the information to JSON when making the API request.

Here's an example .yaml file that shows the required fields and object spec for a Kubernetes Deployment:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

kubectl command-line interface, passing the .yaml file as an argument. Here's an example:
```bash
kubectl apply -f https://k8s.io/examples/application/deployment.yaml --record
```
The output is similar to this:

```bash
deployment.apps/nginx-deployment created
```

# Object Names and IDs
Each object in your cluster has a *Name* that is unique for that type of resource. Every Kubernetes object also has a *UID* that is **unique** across your whole cluster.
For example, you can only have **one** Pod named **myapp-1234** within the same namespace, but you can have one Pod and one Deployment that are each named myapp-1234.

## Names
A client-provided string that refers to an object in a resource URL, such as /api/v1/pods/some-name.

## DNS Subdomain Names 
Most resource types require a name that can be used as a DNS subdomain name as defined in **RFC_1123**. This means the name must:
- Contain no more than 253 characters.
- Contain only lowercase alphanumeric characters, '-' or '.'
- Start with an alphanumeric character.
- End with an alphanumeric character.

## Path Segment Names 
Some resource types require their names to be able to be safely encoded as a path segment. In other words, the name may not be "." or ".." and the name may not contain "/" or "%".

Here's an example manifest for a Pod named nginx-demo
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-demo
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
```

# Namespaces
## When to Use Multiple Namespaces
Namespaces are intended for use in environments with many users spread across multiple teams, or projects.

## Working with Namespaces
> Note: Avoid creating namespaces with the prefix kube-, since it is reserved for Kubernetes system namespaces.

## Viewing namespaces
`kubectl get namespace`
```bash
NAME              STATUS   AGE
default           Active   1d
kube-node-lease   Active   1d
kube-public       Active   1d
kube-system       Active   1d
```
#### Kubernetes starts with four initial namespaces:

`default` The default namespace for objects with no other namespace
`kube-system` The namespace for objects created by the Kubernetes system
 `kube-public` This namespace is created automatically and is
 readable by all users (including those not authenticated). This namespace is mostly reserved for cluster usage, in case that some resources should be visible and readable publicly throughout the whole cluster. The public aspect of this namespace is only a convention, not a requirement.
 `kube-node-lease` This namespace for the lease objects associated with each node which improves the performance of the node heartbeats as the cluster scales.
 
 #### Setting the namespace for a request 
 To set the namespace for a current request, use the `--namespace` flag.
 ```bash
 kubectl run nginx --image=nginx --namespace=<insert-namespace-name-here>
kubectl get pods --namespace=<insert-namespace-name-here>
```

#### Setting the namespace preference
You can permanently save the namespace for all subsequent kubectl commands in that context.
```bash
kubectl config set-context --current --namespace=<insert-namespace-name-here>
# Validate it
kubectl config view --minify | grep namespace:
```
#### Namespaces and DNS 
When you create a Service, it creates a corresponding DNS entry. This entry is of the form `<service-name>.<namespace-name>`**.svc.cluster.local**, which means that if a container only uses `<service-name>`, it will *resolve to the service which is local to a namespace*. This is useful for using the same configuration across multiple namespaces such as Development, Staging and Production. If you want to reach across namespaces, you need to use the fully qualified domain name (FQDN).
#### Not All Objects are in a Namespace
Most Kubernetes resources (e.g. pods, services, replication controllers, and others) are in some namespaces. However namespace resources are not themselves in a namespace. And low-level resources, such as nodes and persistentVolumes, are not in any namespace.
To see which Kubernetes resources are and aren't in a namespace:
```bash
# In a namespace
kubectl api-resources --namespaced=true

# Not in a namespace
kubectl api-resources --namespaced=false
```

